---
title: "Lab 4: Reducing Crime"
author: "Sullivan Swift, Jayanth Srinivasa"
date: "December 4, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(lmtest)
library(sandwich)
library(stargazer)

#Just putting together the inital structure laid out in the lab assignment
```

## 1. Introduction

## 2. Initial exploratory analysis

Detect any anomalies, including missing values, top-coded or bottom-
coded variables, etc.

Model Building Process is supported by exploratory analysis. Your EDA should be interspersed with, and support, your modeling decisions. In particular, you should use exploratory techniques to address

. What transformations to apply to variables and what new variables should be created.

. What variables should be included in each model

1. log(density), polpc
2. 

. Whether model assumptions are met

```{r}
#set working directory
#setwd("C:/Users/Sullivan/Dropbox/W203/Lab 4")
setwd("~/Desktop/data_w203/w203.6Lab4")

#load the data
crime <- read.csv("crime.csv")

#Exploratory data analysis
#data overall
head(crime)
summary(crime)

#county
summary(crime$county)
hist(crime$county)

#crimerate
summary(crime$crmrte)
hist(crime$crmrte)
#long right tail

#police per capita
summary(crime$polpc)
hist(crime$polpc)
#extreme outlier on the right

#density per sq mile
summary(crime$density)
hist(crime$density)
#abrupt cut off on the right at 0, try log
summary(log(crime$density))
hist(log(crime$density))
#better but still not entirely normal
#n > 30, not gonna worry about it

#counties seems like too many numbers to use
#will try west/central or urban as on identifiers 
table(crime$west)
table(crime$central)
table(crime$urban)
#well those numbers aren't equal
#I just don't feel like we can ignore different areas in the state 

#tax revenue per capita
summary(crime$taxpc)
hist(crime$taxpc)
#outlier to the far right, wtf - wonder if it's the same county

#pctmin80 - might be too far back in time? or that's a concern anyway
summary(crime$pctmin80)
hist(crime$pctmin80)

#pctymle - % young male
summary(crime$pctymle)
hist(crime$pctymle)

## Creating a median_wage column :
crime$med_wag <- apply(crime[,(16:24)],1, median, na.rm = TRUE) 
summary(crime$med_wag)
hist(crime$med_wag)

## If we assume the probability of conviction and arrest, is a deterrent to crime we can create a new variable that gives the probability of conviction after arrest, i.e the multiple  of the probability of arrest and probability of conviction.
crime$prbconv_prbarr <-  crime$prbarr*crime$prbconv
summary(crime$prbconv_prbarr)
hist(crime$prbconv_prbarr)

#This clearly shows us that it is skewed and if we take a log of this we get 
crime$log_prbconv_prbarr <- log(crime$prbconv_prbarr)
summary(crime$log_prbconv_prbarr)
hist(crime$log_prbconv_prbarr)


#leaving out prison sentences and mix - they seem like the outcome variables mentioned below

#correlations and scatterplots
#I'm not like totally sure if we need to check log(density) in these
(c <- with(crime, cor(cbind(crmrte, polpc, density, log(density), taxpc, pctmin80, pctymle))))
#density and crime rate are the only ones super correlated (.73), crime rate and tax per capita are .45, which isn't bad but isn't great. density x taxpc = .32

scatterplotMatrix(crime[,c('crmrte', 'polpc', 'density', 'taxpc', 'pctmin80', 'pctymle')])
```


## 4. Three model specifications

One model with only the explanatory variables of key interest (possibly transformed, as determined by your EDA), and no other covariates.
```{r}
#1. crmrte ~ log(density) + polpc
```
. One model that includes key explanatory variables and only covariates that you believe increase the accuracy of your results without introducing bias (for example, you should not include outcome variables that will absorb some of the causal effect you are interested in). This model should strike a balance between accuracy and parsimony and reflect your best understanding of the determinants of crime.
```{r}
#2. crmrte ~ log(density) + polpc + pctymle
```
. One model that includes the previous covariates, and most, if not all, other covariates. A key purpose of this model is to demonstrate the robustness of your results to model specification.
```{r}
#3. crmrte ~ log(density) + polpc + pctymle + pctmin80 + taxpc + (maybe something location wise? the wages maybe? <- need to do EDA for wages)
#4. crmrte ~ log(density) + med_wage + log_prbconv_prbarr ?
```
## 5. Test 6 CLM

For additional models, you
should check all assumptions, but only highlight major differences from your first model in your report.
1. Linear Model
2. Random Sample
3. No perfect colinearity
4. Zero Conditional mean
4'. Exogeneity (I don't think we need to worry about this one?)
5. Homoskedasticity
6. IID normal error

## 6. Well formatted regression table (Stargazer?)

Make sure that standard errors presented in this table are valid. Also, be sure to comment on both statistical and practical significance.

```{r}

#1. Linear

# 2. Random sampling
durbinWatsonTest(model)

#3. no perfect multicolinearity
(c <- with(crime, cor(cbind(crmrte, polpc, density, log(density), taxpc, pctmin80, pctymle))))

# 4. Zero-conditional mean
plot(model)

#fitted v redisuals

#5. homoskedasticity
# scale location plot

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
```

## 7. Discussion of Causality

In particular, include a discussion of what variables are not included in your analysis and the likely direction of omitted variable bias. Highlight any coefficients you find that appear to have the wrong sign from a causal perspective, and explain why this is the case.

## 8. Brief Conclusion with high-level takeaways
