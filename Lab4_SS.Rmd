---
title: 'Lab 4: Reducing Crime'
author: "Sullivan Swift, Jayanth Srinivasa"
date: "December 4, 2017"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(lmtest)
library(sandwich)
library(stargazer)

#set working directory
setwd("C:/Users/Sullivan/Dropbox/W203/Lab 4")

#load the data
crime <- read.csv("crime.csv")

variable <- c("county",
              "year",
              "crmrte",
              "prbarr",
              "prbconv",
              "prbpris",
              "avgsen",
              "polpc",
              "density",
              "taxpc",
              "west",
              "central",
              "urban",
              "pctmin80",
              "wcon",
              "wtuc",
              "wtrd",
              "wfir",
              "wser",
              "wmfg",
              "wfed",
              "wsta",
              "wloc",
              "mix",
              "pctymle")

label <- c("county identifier",
           "1987",
           "crimes committed per person",
           "`probability` of arrest",
           "`probability` of conviction",
           "`probability` of prison sentence",
           "avg. sentence, days",
           "police per capita ",
           "people per sq. mile",
           "tax revenue per capita",
           "=1 if in western N.C.",
           "=1 if in central N.C.",
           "=1 if in SMSA",
           "perc. minority, 1980",
           "weekly wage, construction",
           "wkly wge, trns, util, commun",
           "wkly wge, whlesle, retail trade",
           "wkly wge, fin, ins, real est",
           "wkly wge, service industry",
           "wkly wge, manufacturing",
           "wkly wge, fed employees",
           "wkly wge, state employees",
           "wkly wge, local gov emps",
           "offense mix: face-to-face/other",
           "percent young male")

desc <- data.frame(variable, label)
```

## 1. Introduction and Exploratory Analysis

To address questions regarding the determinants of crime in North Carolina in 1987, we conducted an analysis of the state's crime rate and possible related varaibles, including the following:

```{r}
#list the variables
desc
nrow(crime)
summary(crime) #No null values
```

We examined variables crime rate (`crmrte`), density per square mile (`density`), tax revenue per capita (`taxpc`), percent minority in 1980 (`pctmin80`), percent young male (`pctymle`), and probability of arrest (`prbarr`) as our main variables of interest. First, we performed a high level analysis to assess the quality of our data. We also wanted to examine wage data, so we calculated the median weekly wage (`med_wag`) for each county.

```{r, include=FALSE}
crime$med_wag <- apply(crime[,(16:24)],1, median, na.rm = TRUE)

C <- crime
filter = !is.na(C$crmrte) | !is.na(C$density) | !is.na(C$taxpc) | !is.na(C$pctmin80) | !is.na(C$pctymle) | !is.na(C$med_wag)
C = C[filter,]
summary(C)
nrow(C)

table(crime$west)
table(crime$central)
table(crime$urban)
```

There are no NA values. We also wanted to incorporate location into the analysis but these three variables did not create groups of even n, so we did not include location data in the analysis.

```{r}
summary(crime$crmrte)
hist(crime$crmrte, breaks=50,
     main="Histogram of crmrate")

summary(log(crime$crmrte))
hist(log(crime$crmrte), breaks=50,
     main="Histogram of log(crmrte)")

crime$log_crmrte <- log(crime$crmrte)
```

First we analyzed the outcome variable, crime rate(`crmrte`). In the original `crmrte` variable, the distribution is right tailed. We applied a log transformation to `crmrte`, and this variable had a more normal distribution. We chose to use the log of `crmrte` in our models below.

```{r}
summary(crime$density)
hist(crime$density, breaks=50,
     main="Histogram of Density per sq mile")

summary(log(crime$density))
hist(log(crime$density), breaks=50,
     main="Histogram of log(density)")

crime$log_density <- log(crime$density)
```

Next we examined density per square mile (`density`). There is a positive skew, so we again applied a log transformation. The log transformation of `density` is not quite normal, but since our $n=90$, we can rely on the Central Limit Theorem.

```{r}
summary(crime$taxpc)
hist(crime$taxpc, breaks=50,
     main="Histogram of Tax Paid per Capita")

summary(crime$med_wag)
hist(crime$med_wag, breaks=50,
     main="Histogram of Median Wages")
```

We then analyzed tax paid per capita (`taxpc`) and median wage (`med_wag`). 

need to make some argument here about how they are potentially measuring too much of the same thing.

```{r}
summary(crime$pctmin80)
hist(crime$pctmin80, breaks=50,
     main="Histogram of Percent Minority in 1980")
hist(log(crime$pctmin80), breaks=50,
     main="Histogram of Percent Minority in 1980")
```

Next, we looked at percent minority in 1980 (`pctmin80`). 

```{r}
#pctymle - % young male
summary(crime$pctymle)
hist(crime$pctymle, breaks=50,
     main="Histogram of Percent Young Male")
#values are very low - they're in a percent format
#it increases on the .01-.1 scale 
#no zeros, take log
summary(log(crime$pctymle))
hist(log(crime$pctymle), breaks=50,
     main="Histogram of log(pctymle)")
#slightly more normal
crime$log_pctymle <- log(crime$pctymle)
```

`pctymle` appears to be the decimal format of a percentage. 

```{r}
summary(crime$prbarr)
hist(log(crime$prbarr), breaks=50,
     main="Histogram of Probability of Arrest")
```

Addressing the linearity assumption, the models we create below are linear in nature, so we meet this assumption.

Our sample appears to be nearly the entire population, and we ran into no NA values above. North Carolina has 100 counties, and our dataset contains 90. It contains enough of the population for us to make/bypass? the assumption of random sampling.

```{r}
scatterplotMatrix(crime[,c('crmrte', 'density', 'med_wag', 'taxpc', 'pctmin80', 'pctymle', 'prbarr')])

(c <- with(crime, cor(cbind(crmrte, density, log_density, med_wag, taxpc, pctmin80, pctymle,log_pctymle, prbarr))))
```

We examined a scatterplot matrix and a correlation matrix to assess the next assumption, no perfect multicollinearity. None of the variables we examined have a perfect correlation. Density has a fairly strong correlation with the `crmrte`, and so we used `density` as a key variable in our models below. We chose to include `med_wag`, but not `taxpc`. We chose to include pctmin80, and the transformation log(`pctymle`) over pctymle. 

We chose to use XYZ variables in the modeling analysis

## Modeling Crime Rate

One model with only the explanatory variables of key interest (possibly transformed, as determined by your EDA), and no other covariates.
```{r}
#SS
#1. log(crmrte) ~ log(density)
(model1 <- lm(log(crmrte) ~ log(density), data=crime))
plot(model1)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model1 = sqrt(diag(vcovHC(model1))))

# 4'. Exo/Endogeneity
plot(model1, which=1)
plot(model1, which=5)
(cov(log(crime$density), model1$residuals))
#There is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the residuals v fitted: fairly consistent but there are few data points on the extremes
#There is a small amount of edivdence for a violation, we will be cautious and use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model1$residuals, breaks = 100)
#normal, supporting IID
#qq plot, fairly normal except in extremes
```
. One model that includes key explanatory variables and only covariates that you believe increase the accuracy of your results without introducing bias (for example, you should not include outcome variables that will absorb some of the causal effect you are interested in). This model should strike a balance between accuracy and parsimony and reflect your best understanding of the determinants of crime.
```{r}
#SS
#2. log(crmrte) ~ log(density) + mpercent young males + pencent minority in 1980
(model2 <- lm(log(crmrte) ~ log(density) + log(pctymle) + pctmin80, data=crime))
plot(model2)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model2 = sqrt(diag(vcovHC(model2))))

# 4'. Exo/Endogeneity
plot(model2, which=1)
plot(model2, which=5)
(cov(log(crime$density), model2$residuals))
(cov(log(crime$pctymle), model2$residuals))
(cov(crime$pctmin80, model2$residuals))
#There is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0 - same as model 1


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the residuals v fitted: fairly consistent but is more varied on the extremes then model1
#There is a small amount of edivdence for a violation, we will be cautious and use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model2$residuals, breaks = 100)
#normal, supporting IID
#qq plot, fairly normal except in extremes - more normal than model1
```
. One model that includes the previous covariates, and most, if not all, other covariates. A key purpose of this model is to demonstrate the robustness of your results to model specification.
```{r}
#JS
#3. log(crmrte) ~ log(density) + pctymle + pctmin80 + taxpc + (maybe something location wise? the wages maybe? <- need to do EDA for wages)
(model3 <- lm(log(crmrte) ~ log(density) + log(pctymle) + pctmin80 + med_wag + log(prbarr), data=crime))
plot(model3)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model3 = sqrt(diag(vcovHC(model3))))

# 4'. Exo/Endogeneity
plot(model3, which=1)
plot(model3, which=5)
(cov(log(crime$density), model3$residuals))
(cov(log(crime$pctymle), model3$residuals))
(cov(crime$pctmin80, model3$residuals))
(cov(crime$med_wag, model3$residuals))
(cov(log(crime$prbarr), model3$residuals))
#all have is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0 - same as model 1
#left side has one point that pulls the mean down, otherwise zero mean


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the scale location: definitely heteroskedastic 
#use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model3$residuals, breaks = 100)
#normal, supporting IID - has two fairly extreme points but mostly is together & normal
#qq plot, better fit than model 1 on the whole but has two very far outliers
```
## 6. Well formatted regression table (Stargazer?)

Make sure that standard errors presented in this table are valid. Also, be sure to comment on both statistical and practical significance.

```{r}
#JS
stargazer(model1, model2, model3, type = "text", omit.stat = "f",
          se = list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001))
#model1
#significant on log(density) at the .001 level. cool. practical & statistical

#model2
#two .01 level significance 
# holding all other things constant
#log(density) remains significant supporting it's use in the model - for each % change in density, there is a .51% change in crmrte
#practically and statistically significant
#log(pctmale) is also signicicant at the .001 level - for each % change in pctymle, there is a .388% change in crmrte
#pctmin80 significant - for each unit change in pctmin80, there is a 1.2% change in crmrte
#seems to be the best
#practically significant - almost a one to one increase

#model3
#very similar interpretation to moel 2 + two insiginificant additional vairables
#log(density) remains significant supporting it's use in the model - for each % change in density, there is a .48% change in crmrte
#practically and statistically significant
#log(pctmale) is also signicicant at the .05 level - for each % change in pctymle, there is a .277% change in crmrte
#pctmin80 significant - for each unit change in pctmin80, there is a 1.2% change in crmrte
#med wage - not siginificant - the beta is negative - for each unit change (thousands of dollars) in med_wag, there is a -.1% change in crmrte
#would be practically significant, but not statistically significant
#log(prbarr) - not significant - the beta is negative - or each % change in density, there is a -.249% change in crmrte
#would be practically signgifcant
#because the additional variables are not significant, we have support for using model 2

```

## 7. Discussion of Causality

In particular, include a discussion of what variables are not included in your analysis and the likely direction of omitted variable bias. Highlight any coefficients you find that appear to have the wrong sign from a causal perspective, and explain why this is the case.

I don't think we can talk in terms of causality. the data isn't collected in an experiment format, it's observational. 

## 8. Brief Conclusion with high-level takeaways

