---
title: "Lab 4: Reducing Crime"
author: "Sullivan Swift, Jayanth Srinivasa"
date: "December 4, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(lmtest)
library(sandwich)
library(stargazer)

#set working directory
setwd("C:/Users/Sullivan/Dropbox/W203/Lab 4")

#load the data
crime <- read.csv("crime.csv")

variable <- c("county",
              "year",
              "crmrte",
              "prbarr",
              "prbconv",
              "prbpris",
              "avgsen",
              "polpc",
              "density",
              "taxpc",
              "west",
              "central",
              "urban",
              "pctmin80",
              "wcon",
              "wtuc",
              "wtrd",
              "wfir",
              "wser",
              "wmfg",
              "wfed",
              "wsta",
              "wloc",
              "mix",
              "pctymle")

label <- c("county identifier",
           "1987",
           "crimes committed per person",
           "‘probability’ of arrest",
           "‘probability’ of conviction",
           "‘probability’ of prison sentence",
           "avg. sentence, days",
           "police per capita ",
           "people per sq. mile",
           "tax revenue per capital",
           "=1 if in western N.C.",
           "=1 if in central N.C.",
           "=1 if in SMSA",
           "perc. minority, 1980",
           "weekly wage, construction",
           "wkly wge, trns, util, commun",
           "wkly wge, whlesle, retail trade",
           "wkly wge, fin, ins, real est",
           "wkly wge, service industry",
           "wkly wge, manufacturing",
           "wkly wge, fed employees",
           "wkly wge, state employees",
           "wkly wge, local gov emps",
           "offense mix: face-to-face/other",
           "percent young male")

desc <- data.frame(variable, label)
```

## 1. Introduction

To address questions regarding the determinants of crime in North Carolina in 1987, we conducted an analysis of the state's crime rate and possible related varaibles, including the following:

```{r}
#list the variables
desc
nrow(crime)
summary(crime) #No null values
```

We examined variables `crmrte`, `polpc`, `density`, `taxpc`, `pctmin80`, and `pctymle` [SS/JS: ADD OTHER VARIABLES]. First, we performed a high level analysis to assess the quality of our data.

```{r, include=FALSE}
#Check for NAs UPDATE
C <- crime
filter = !is.na(C$crmrte) | !is.na(C$polpc) | !is.na(C$density) | !is.na(C$taxpc) | !is.na(C$pctmin80) | !is.na(C$pctymle)
C = C[filter,]
summary(C)
nrow(C)
```



```{r}
#SS
summary(crime)

#county
summary(crime$county)
hist(crime$county)

#crimerate
summary(crime$crmrte)
hist(crime$crmrte)
#long right tail
summary(log(crime$crmrte))
hist(log(crime$crmrte))
#makes it more normal

#police per capita
summary(crime$polpc)
hist(crime$polpc)
#extreme outlier on the right

#density per sq mile
summary(crime$density)
hist(crime$density)
#abrupt cut off on the right at 0, try log
summary(log(crime$density))
hist(log(crime$density))
#better but still not entirely normal
#n > 30, not gonna worry about it

#counties seems like too many numbers to use
#will try west/central or urban as on identifiers 
table(crime$west)
table(crime$central)
table(crime$urban)
#well those numbers aren't equal
#I just don't feel like we can ignore different areas in the state 

#tax revenue per capita
summary(crime$taxpc)
hist(crime$taxpc, breaks = 100)
#outlier to the far right, wtf - wonder if it's the same county

summary(log(crime$taxpc))
hist(log(crime$taxpc), breaks = 100)

#pctmin80 - might be too far back in time? or that's a concern anyway
summary(crime$pctmin80)
hist(crime$pctmin80)

#pctymle - % young male
summary(crime$pctymle)
hist(crime$pctymle, breaks=100)
#values are very low - they're in a percent format
#it increases on the .01-.1 scale 
#no zeros, take log
summary(log(crime$pctymle))
hist(log(crime$pctymle), breaks=100)
#slightly more normal

## Creating a median_wage column :
crime$med_wag <- apply(crime[,(16:24)],1, median, na.rm = TRUE)
summary(crime$med_wag)
hist(crime$med_wag)
hist(log(crime$med_wag))

## If we assume the probability of conviction and arrest, is a deterrent to crime we can create a new variable that gives the probability of conviction after arrest, i.e the multiple  of the probability of arrest and probability of conviction.
crime$prbconv_prbarr <-  crime$prbarr*crime$prbconv
summary(crime$prbconv_prbarr)
hist(crime$prbconv_prbarr)

summary(crime$prbarr)
hist(log(crime$prbarr), breaks=100)
summary(crime$prbconv)
cor(crime$crmrte, crime$prbarr)
plot(crime$prbarr, crime$crmrte)

#This clearly shows us that it is skewed and if we take a log of this we get 
crime$log_prbconv_prbarr <- log(crime$prbconv_prbarr)
summary(crime$log_prbconv_prbarr)
hist(crime$log_prbconv_prbarr)

#leaving out prison sentences and mix - they seem like the outcome variables mentioned below

#Assumptions to address
#1. Linear
#The models we have proposed are linear in nature.

# 2. Random sampling
#We don't need to worry about this assumption, we have the complete data set
durbinWatsonTest(model)

#3. no perfect multicolinearity
(c <- with(crime, cor(cbind(crmrte, density, log(density), med_wag, log(med_wag), taxpc, log(taxpc), pctmin80, pctymle))))
#We used a correlation matrix, and no two variables had a perfect correlation.
```

## 2. Initial exploratory analysis

Detect any anomalies, including missing values, top-coded or bottom-
coded variables, etc.

Model Building Process is supported by exploratory analysis. Your EDA should be interspersed with, and support, your modeling decisions. In particular, you should use exploratory techniques to address

. What transformations to apply to variables and what new variables should be created.

. What variables should be included in each model

. Whether model assumptions are met

```{r}
#SS
#correlations and scatterplots
#I'm not like totally sure if we need to check log(density) in these
(c <- with(crime, cor(cbind(crmrte, density, log(density), med_wag, log(med_wag), taxpc, log(taxpc), pctmin80, pctymle))))
#density and crime rate are the only ones super correlated (.73), crime rate and tax per capita are .45, which isn't bad but isn't great. density x taxpc = .32

scatterplotMatrix(crime[,c('crmrte', 'polpc', 'density', 'med_wag', 'taxpc', 'pctmin80', 'pctymle')])
```


## 4. Three model specifications

One model with only the explanatory variables of key interest (possibly transformed, as determined by your EDA), and no other covariates.
```{r}
#SS
#1. log(crmrte) ~ log(density)
(model1 <- lm(log(crmrte) ~ log(density), data=crime))
plot(model1)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model1 = sqrt(diag(vcovHC(model1))))

# 4'. Exo/Endogeneity
plot(model1, which=1)
plot(model1, which=5)
(cov(log(crime$density), model1$residuals))
#There is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the residuals v fitted: fairly consistent but there are few data points on the extremes
#There is a small amount of edivdence for a violation, we will be cautious and use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model1$residuals, breaks = 100)
#normal, supporting IID
#qq plot, fairly normal except in extremes
```
. One model that includes key explanatory variables and only covariates that you believe increase the accuracy of your results without introducing bias (for example, you should not include outcome variables that will absorb some of the causal effect you are interested in). This model should strike a balance between accuracy and parsimony and reflect your best understanding of the determinants of crime.
```{r}
#SS
#2. log(crmrte) ~ log(density) + mpercent young males + pencent minority in 1980
(model2 <- lm(log(crmrte) ~ log(density) + log(pctymle) + pctmin80, data=crime))
plot(model2)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model2 = sqrt(diag(vcovHC(model2))))

# 4'. Exo/Endogeneity
plot(model2, which=1)
plot(model2, which=5)
(cov(log(crime$density), model2$residuals))
(cov(log(crime$pctymle), model2$residuals))
(cov(crime$pctmin80, model2$residuals))
#There is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0 - same as model 1


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the residuals v fitted: fairly consistent but is more varied on the extremes then model1
#There is a small amount of edivdence for a violation, we will be cautious and use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model2$residuals, breaks = 100)
#normal, supporting IID
#qq plot, fairly normal except in extremes - more normal than model1
```
. One model that includes the previous covariates, and most, if not all, other covariates. A key purpose of this model is to demonstrate the robustness of your results to model specification.
```{r}
#JS
#3. log(crmrte) ~ log(density) + pctymle + pctmin80 + taxpc + (maybe something location wise? the wages maybe? <- need to do EDA for wages)
(model3 <- lm(log(crmrte) ~ log(density) + log(pctymle) + pctmin80 + med_wag + log(prbarr), data=crime))
plot(model3)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model3 = sqrt(diag(vcovHC(model3))))

# 4'. Exo/Endogeneity
plot(model3, which=1)
plot(model3, which=5)
(cov(log(crime$density), model3$residuals))
(cov(log(crime$pctymle), model3$residuals))
(cov(crime$pctmin80, model3$residuals))
(cov(crime$med_wag, model3$residuals))
(cov(log(crime$prbarr), model3$residuals))
#all have is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0 - same as model 1
#left side has one point that pulls the mean down, otherwise zero mean


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the scale location: definitely heteroskedastic 
#use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model3$residuals, breaks = 100)
#normal, supporting IID - has two fairly extreme points but mostly is together & normal
#qq plot, better fit than model 1 on the whole but has two very far outliers
```
## 6. Well formatted regression table (Stargazer?)

Make sure that standard errors presented in this table are valid. Also, be sure to comment on both statistical and practical significance.

```{r}
#JS
stargazer(model1, model2, model3, type = "text", omit.stat = "f",
          se = list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001))
#model1
#significant on log(density) at the .001 level. cool. practical & statistical

#model2
#two .01 level significance 
# holding all other things constant
#log(density) remains significant supporting it's use in the model - for each % change in density, there is a .51% change in crmrte
#practically and statistically significant
#log(pctmale) is also signicicant at the .001 level - for each % change in pctymle, there is a .388% change in crmrte
#pctmin80 significant - for each unit change in pctmin80, there is a 1.2% change in crmrte
#seems to be the best
#practically significant - almost a one to one increase

#model3
#very similar interpretation to moel 2 + two insiginificant additional vairables
#log(density) remains significant supporting it's use in the model - for each % change in density, there is a .48% change in crmrte
#practically and statistically significant
#log(pctmale) is also signicicant at the .05 level - for each % change in pctymle, there is a .277% change in crmrte
#pctmin80 significant - for each unit change in pctmin80, there is a 1.2% change in crmrte
#med wage - not siginificant - the beta is negative - for each unit change (thousands of dollars) in med_wag, there is a -.1% change in crmrte
#would be practically significant, but not statistically significant
#log(prbarr) - not significant - the beta is negative - or each % change in density, there is a -.249% change in crmrte
#would be practically signgifcant
#because the additional variables are not significant, we have support for using model 2

```

## 7. Discussion of Causality

In particular, include a discussion of what variables are not included in your analysis and the likely direction of omitted variable bias. Highlight any coefficients you find that appear to have the wrong sign from a causal perspective, and explain why this is the case.

I don't think we can talk in terms of causality. the data isn't collected in an experiment format, it's observational. 

## 8. Brief Conclusion with high-level takeaways

