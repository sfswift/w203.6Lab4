---
title: 'Lab 4: Reducing Crime'
author: "Sullivan Swift, Jayanth Srinivasa"
date: "December 4, 2017"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(lmtest)
library(sandwich)
library(stargazer)

#set working directory
setwd("C:/Users/Sullivan/Dropbox/W203/Lab 4")
#setwd("~/Desktop/data_w203/w203.6Lab4")

#load the data
crime <- read.csv("crime.csv")

#replicate description of variables
variable <- c("county",
              "year",
              "crmrte",
              "prbarr",
              "prbconv",
              "prbpris",
              "avgsen",
              "polpc",
              "density",
              "taxpc",
              "west",
              "central",
              "urban",
              "pctmin80",
              "wcon",
              "wtuc",
              "wtrd",
              "wfir",
              "wser",
              "wmfg",
              "wfed",
              "wsta",
              "wloc",
              "mix",
              "pctymle")

label <- c("county identifier",
           "1987",
           "crimes committed per person",
           "`probability` of arrest",
           "`probability` of conviction",
           "`probability` of prison sentence",
           "avg. sentence, days",
           "police per capita ",
           "people per sq. mile",
           "tax revenue per capita",
           "=1 if in western N.C.",
           "=1 if in central N.C.",
           "=1 if in SMSA",
           "perc. minority, 1980",
           "weekly wage, construction",
           "wkly wge, trns, util, commun",
           "wkly wge, whlesle, retail trade",
           "wkly wge, fin, ins, real est",
           "wkly wge, service industry",
           "wkly wge, manufacturing",
           "wkly wge, fed employees",
           "wkly wge, state employees",
           "wkly wge, local gov emps",
           "offense mix: face-to-face/other",
           "percent young male")

desc <- data.frame(variable, label)
```

## Introduction

To address questions regarding the determinants of crime in North Carolina in 1987, we conducted an analysis of the state's crime rate and possible related varaibles, including many of the following:

```{r}
#description of the variables in the crime dataset
desc
#nmber of rows
nrow(crime)
summary(crime)
```

To address the question regarding the causes of crime, we examined variables crime rate (`crmrte`), density per square mile (`density`), tax revenue per capita (`taxpc`), percent minority in 1980 (`pctmin80`), percent young male (`pctymle`), and probability of arrest (`prbarr`) as our main variables of interest. We also wanted to examine wage data, so we calculated the median weekly wage (`med_wag`) for each county. We believe these variables will give us a wholistic view of each county in terms of population density, demographics, and wealth.

First, we created our new `med_wag` variable, and performed a high level analysis to assess the quality of our data.

```{r}
#Take the median for each county from all wage variables.
crime$med_wag <- apply(crime[,(16:24)], 1, median, na.rm=TRUE)

#check for NAs among key variables
C <- crime
filter = !is.na(C$crmrte) | !is.na(C$density) | !is.na(C$taxpc) | !is.na(C$pctmin80) | !is.na(C$pctymle) | !is.na(C$med_wag)
C = C[filter,]
summary(C)
nrow(C)

#review the aggregate location data
table(crime$west)
table(crime$central)
table(crime$urban)
summary(crime$county)
```

There are no NA values, so we were able to continue with the complete dataset. Above we briefly examined location data. We originally wanted to incorporate location into the analysis, but these three variables did not create groups of even $n$ and the `county` variable is too granular on its own, so we did not include location data in the analysis.

```{r}
#examine key outcome variable, crmrte
summary(crime$crmrte)
hist(crime$crmrte, breaks=50,
     main="Histogram of crmrate")

#apply log transformation
summary(log(crime$crmrte))
hist(log(crime$crmrte), breaks=50,
     main="Histogram of log(crmrte)")

#store transformation
crime$log_crmrte <- log(crime$crmrte)
```

First we analyzed the outcome variable, crime rate (`crmrte`). In the original `crmrte` variable, the distribution is right tailed. We applied a log transformation to `crmrte`, and this variable had a more normal distribution. We chose to use the log of `crmrte` as our outcome variable in the models below.

```{r}
#examine predictor variable, density
summary(crime$density)
hist(crime$density, breaks=50,
     main="Histogram of Density per sq mile")

#apply log transformation
summary(log(crime$density))
hist(log(crime$density), breaks=50,
     main="Histogram of log(density)")

#store transformation
crime$log_density <- log(crime$density)
```

Next we examined density per square mile (`density`). There is a positive skew, so we again applied a log transformation. The log transformation of `density` is not quite normal, but since our $n=90$, we can rely on the Central Limit Theorem.

```{r}
#examine predictor variable, taxpc
summary(crime$taxpc)
hist(crime$taxpc, breaks=50,
     main="Histogram of Tax Revenue per Capita")

#examine predictor variable, med_wag
summary(crime$med_wag)
hist(crime$med_wag, breaks=50,
     main="Histogram of Median Wages")
```

We then analyzed tax revenue per capita (`taxpc`) and median wage (`med_wag`). We were concerned that these two variables have too much overlap in effect - wages are likely a very similar measure to the tax revenue per capita. After looking at the histograms of these two variables, we chose `med_wage` over `taxpc` because it is closer to a normal distribution on its own and will be more clear to interpret in our models below.

```{r}
#examine predictor variable, pctmin80
summary(crime$pctmin80)
hist(crime$pctmin80, breaks=50,
     main="Histogram of Percent Minority in 1980")

#apply log transformation
summary(log(crime$pctmin80))
hist(log(crime$pctmin80), breaks=50,
     main="Histogram of log(pctmin80)")
```

Next, we looked at percent minority in 1980 (`pctmin80`). This data's distribution was not normal, so we applied a log transformation. This caused a left skew to the data, and we chose to continue with the untransformed variable, relying on the Central Limit Theorem for normality.

```{r}
#examine predictor variable, pctymle
summary(crime$pctymle)
hist(crime$pctymle, breaks=50,
     main="Histogram of Percent Young Male")

#apply log transformation
summary(log(crime$pctymle))
hist(log(crime$pctymle), breaks=50,
     main="Histogram of log(pctymle)")

#store transformation
crime$log_pctymle <- log(crime$pctymle)
```

Then we examined the percentage of young males variable (`pctymle`). The values were all very small, between .06 and .25, and it appears to be in a decimal percentage format. `pctymle` also has a right skew. To address the skew, we used a log transformed `pctymle`. Using a log transformation we can also more easily interpret `pctymle` below in our models. 

```{r}
#examine predictor variable, prbarr
summary(crime$prbarr)
hist(crime$prbarr, breaks=50,
     main="Histogram of Probability of Arrest")

#apply log transformation
summary(log(crime$prbarr))
hist(log(crime$prbarr), breaks=50,
     main="Histogram of log(prbarr)")

#store transformation
crime$log_prbarr <- log(crime$prbarr)
```

Lastly, we examined the probability of arrest (`prbarr`). While it is not as skewed as the rest, log(`prbarr`) is still slightly skewed to the right and has one fairly large outlier, so we decided to apply the log transform to this variable. The log transformation has a much more normal distribution.

```{r}
#scatterplot matrix
scatterplotMatrix(crime[,c('crmrte', 'density', 'med_wag', 'taxpc', 'pctmin80', 'pctymle', 'prbarr')])

#correlation matrix
(c <- with(crime, cor(cbind(crmrte, density, log_density, med_wag, taxpc, pctmin80, pctymle,log_pctymle, prbarr))))
```

Finally we examined a scatterplot matrix and correlation matrix to quickly assess the relationships between our variables. None of the variables we examined have a perfect correlation, though some have fairly strong relationships. Density has a strong correlation with the `crmrte`. We used `density` as a key variable in our models below for its intutive relationship to `crmrte` as well as the corrlational relationship. We chose to include `med_wag`, but not `taxpc`, as `med_wag` has a more normal distribution and has a more clear interpretation. We chose to include `pctmin80`, and the transformation log(`pctymle`) over `pctymle`. We can use this correlation matrix to confirm MLR3, no perfect multicollinearity, for our models below.

## Modeling Crime Rate and Addressing Assumptions

Addressing MLR1, the linearity assumption, the three models we create below are linear in nature, so we meet this assumption.

Our sample appears to be nearly the entire population, and we ran into no NA values above. North Carolina has 100 counties, and our dataset contains 90. Enough of the population is included in the dataset for us to assume MLR2, the assumption of random sampling.

We addressed MLR3 above.

### Model 1 

We defined our first model hoping to use only one or two key variables. We settled on log(`crmrte`) ~ log(`density`), as the more densely populated an area, the opportunity for crime to occur increases both from increased individuals and increased property in an area. Above we also see that `density` has a strong, positive correlation with `crmrte`.

```{r}
#create the model
(model1 <- lm(log_crmrte ~ log_density, data=crime))
```

First, we create the model (`model1`) and examine its coefficients. For each 1% increase in `density`, there is a .49% increase in `crmrte`.

```{r}
#examine the covariance between the predictor and the residuals
cov(crime$log_density, model1$residuals)
```

Examining the covariance, we see a very small relationship between `log_density` and `model1`'s residuals. This supports exogeneity. 

```{r}
#resdiuals v fitted values plot
plot(model1, which=1)
```

Next we examine the Residuals v Fitted plot to assess MRL4, the zero-conditional mean assumption. We see that the red spline line is very close to zero through the whole graph. The exception is the small uptick on the far left, but this is likely due to few data points.

```{r}
#scale-location plot
plot(model1, which=3)

#breusch-pagan test
bptest(model1)
#score-test
ncvTest(model1)

#heteroskedatic robust standard errors
se.model1 = sqrt(diag(vcovHC(model1)))
```

To assess MLR5, the homoskedasticity assumption, we look at the Residuals v Fitted plot above, as well as the Scale-Location plot. On both plots, the band of data points narrows as we move right on the graphs, providing evidience of a violation of homoskedasticity. Further supporting this violation, the Breusch-Pagan test and the Score-test both have significant p-values (bptest, $p=.01$; score-test, $p=.005$). Our sample is $n>30$, however the sample is not extremely large. We will use the robust standard errors we have produced above to address the posibility of heteroskedasticity.

```{r}
#residuals vs leverage plot
plot(model1, which=5)
```

Throughout out analysis above, we noticed there was at least one quite large outlier. Here we looked at the Residuals v Leverage plot to determine if we need to remove this data point. The outlier fall inside of the Cook's distnace and does not appear to have any sizable bearing on `model1`, so we may leave it in our analysis.

```{r}
#qqplot
plot(model1, which=2)

#histogram of Model1 residuals
hist(model1$residuals, breaks=50,
     main="Histogram of Model1 Residuals")
```

When assessing MLR6, we examine the Q-Q plot of the model. Here, we can see that the data closely hugs the diagonal, indicating normal residuals. The histogram of the residuals also supports this conclusion. Both charts a few values on the extremes that vary, but on the whole support MLR6.

Next, we ran a summary on `model1` and used our standard errors that are robust to heteroskedasticity.

```{r}
(s1 <- summary(model1))
s1$coefficients[, 2] <- sqrt(diag(vcovHC(model1)))
s1
```

We noticed that the R-squared value was `s1$r.squared`

### Model 2 

Next, we wanted to expand our model with more independent variables, and we chose to add `pctymle` and `pctmin80` incorporate some demographic information in our model. Since the `pctymle` distribution was skewed from the analysis of the histogram, we decided to use the log form of the variable in the analysis. The percent of young males (`pctymle`) and the percent minority in 1980 (`pctmin80`) are both reasonable variables to include in this model as they tell us about the demographic diversity of a county. Though the `pctmin80` data is 7 years old, we chose to include it in our model so we could somewhat assess racial diversity.

```{r}
#create the model
(model2 <- lm(log_crmrte ~ log_density + log_pctymle + pctmin80, data=crime))
```

From examining the coefficients we see that, with everything else being held a constant an increase of 1% in `density`, we see an increase of 0.5% in the crime rate. Similary, an increase in `pctymle` with everything else being constant, produces an increase of crime rate by 0.38% and finally any increase of minority population by 1 unit, results in a nearly 1% increase in the crime rate. 

Now let us check the remaining assumptions. First, we will double check MLR3 with the variable's Variance Inflation Factors. Then we will examine the zero conditional mean assumption by looking at the plot of residuals vs fitted values.

```{r}
#Variance Inflation Factors
vif(model2)

#residuals v fitted values plot
plot(model2, which=1)
```

The VIF values are low, less than 10, supporting the MLR3 assumption. The red spline line is close to zero for all the fitted values, with only a small downturn on the left side. Compared to `model1`, the red spline line appears to fit zero better. This supports making the MLR4 assumption.

```{r}
#examine covariance of predictor variables and model residuals
cov(crime$log_density, model2$residuals)
cov(crime$log_pctymle, model2$residuals)
cov(crime$pctmin80, model2$residuals)
```

The covariance between each of the independent variables and the model residuals are each very small, and it is clear that exogenity assumption holds.

To assess homoskedasticity, we looked at the graph of standardized residuals vs the fitted values below.

```{r}
#scale-location plot
plot(model2, which=3)

#breusch-pagan test
bptest(model2)
#score-test
ncvTest(model2)

#heteroskedastic robust standard errors
se.model2 = sqrt(diag(vcovHC(model2)))
```

The graph shows some outliers to the upper left edge and the band seems to narrow as we move to the right, indicating there may be heteroskedasticity.

The Breusch-Pagan test did not yeild significant results ($p>.05$), but the Non-constant Variance Score Test was significant with $p<.001$. We will be conservative and use the robust standard errors we have produced above to address any heteroskedacity in the data, just as in `model1`.

To test the normality of the errors, we examined the Q-Q plot of the residuals and the histogram of the residuals.

```{r}
#qq plot
plot(model2, which=2)

#histogram of model2 residuals
hist(model2$residuals, breaks=50,
     main="Histogram of Model2 Residuals")
```

The Q-Q plot has some variation around the ends, and both the histogram and the Q-Q plot contain an outlier to the far right. The histogram of the residuals is fairly normal, except for the outlier on the far right. `model2` has more variation in the residuals than `model1`, but the evidence is strong enough to support making the MLR6 assumption.

Finally we can examine the summary command, using our heteroskedasticity robust standard errors from above.

```{r}
(s2 <- summary(model2))
s2$coefficients[, 2] <- sqrt(diag(vcovHC(model2)))
s2
```

That the rsquare value has improved to `s2$r.squared` and the adjusted R-square is `s2$adj.r.squared` in Model2. 

### Model 3

We created one more model to include the previous covariates and along with the probability of arrests (`prbarr`) and the median wage (`med_wag`) to assess the robustness of our first models.
  
```{r}
#create the model
(model3 <- lm(log_crmrte ~ log_density + log_pctymle + pctmin80 + med_wag + log_prbarr, data=crime))
```

From the `model3`, we can say that as the population density increases by 1%, the crime rate goes up by 0.4799% with everything else being constant. Similarly, a percentage increase in the fraction of young males in the population by 1% increases the crime rate by 0.27% and an increase in minorities by 1% (compared to their population in 1980), causes an increase in crime-rate by 1.18%. Finally, the two new variables med_wage and probability of arrests, both have a negative effect on the crime rate. And as median wage increases by a unit of 1, the crime-rate decreases by 0.5% and as the probability of arrest goes up by 1%, the crime rate goes down by 0.24%.  

As before, we confirm MLR3 with VIF and examine the plot of residuals vs fitted values to determine the the zero conditional mean assumption.

```{r}
#Variance Inflation Factors
vif(model3)

#residuals vs fitted values plot
plot(model3, which=1)
```

Again, all VIF values are less than 10, supporting the MLR3 assumption. There is no evidence of a violation of MLR4. While the red spline line very close to zero, we also observe that to the left the line seems to move further below zero than in `model2`. This can likely be attributed to fewer data points on the left side of the fitted values.

```{r}
#examine covariance of predictor variables and model residuals
cov(crime$log_density, model3$residuals)
cov(crime$log_pctymle, model3$residuals)
cov(crime$pctmin80, model3$residuals)
cov(crime$med_wag, model3$residuals)
cov(crime$log_prbarr, model3$residuals)
```

Again, the covariance between each of the independent variables and the model residuals are very small, and we again see exogeneity holds.

Next we look at `model3`'s scale-location plot, Breusch-Pagan test, and the Score-test to assess homoskedasticity.

```{r}
#scale-location plot
plot(model3, which=3)
#breusch-pagan test
bptest(model3)
#score-test
ncvTest(model3)

#heteroskedastic robust standard error
se.model3 = sqrt(diag(vcovHC(model3)))
```

The graph clearly shows there are some outliers and there is no band in which the values are found. This shows that the variables are heteroskedactic. Further supporting this violation, the Breusch-Pagan test has significant p-value. We will be conservative and use the robust standard errors we have produced above to address any heteroskedacity in the data.

Again, we examine a Q-Q plot of the residuals and the histogram of the residuals to determine the MLR6 assumption.

```{r}
#qq plot
plot(model3, which=2)

#histogram of model3 residuals
hist(model3$residuals, breaks=50,
     main="Histogram of Model3 Residuals")
```

Both plots show a fairly normal distribution, with a smaller outlier to the left and a larger outlier to the right. `model3`'s residuals histrogram looks marginally more normal than `model2`'s, and MLR6 still holds.

Finally we examine the summary of `model3` with residuals robust to heteroskedasticity.

```{r}
s3 <- summary(model3) 
s3$coefficients[, 2] <- sqrt(diag(vcovHC(model3)))
s3
```

Though the rsquare value has improved to `s3$r.squared` and the adjusted R-square is `s3$adj.r.squared` in `model3`, it hasn't improved all that much in comparison to Model2 and does not justify the addition of the extra variables.

## Comparison of Models

We used the Stargazer library function to compare our three models. Though we see very little evidence of complete heteroskedacity, we would like to be conservative and we are using the robust standard errors for all the three models.

```{r}
#model comparison output with stargazer
stargazer(model1, model2, model3, type = "text", omit.stat = "f",
          se = list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001))
```

From the output above: 

For `model1`, we see that the log_density is statistically significant at $p<.001$ level. Also since we are examining the elasitic relationship between the crimerate and the density of population, we see that for 1% increase in the density of population results in an increase in `crmrte` bye 0.486% . Since this is a pretty observable effect, the `log_density` is practically significant too. 

For `model2`, we see that `log_density`, `log_pctymle`, and `pctmin80` are all statistically significant at the p < 0.001 level. This clearly indicates statistical significance. Also, given everything else is constant, the crime rate increases by 0.5% with every 1% increase in the density of population, increases by 0.38% for every 1% increase in the fraction of the young male population and finally the crimerate will increase by 1.2% when the minority population increases by 1% over the 1980 value. The value of change signifies a practical significance too. 

For `model3`, we see that the `log_density`,  `pctmin80` are statistically significant at the p < 0.001 level, `log_pctymle` is statistically significant at the 0.01 level, but med_wag and log_prbarr are not statistically signficant. Practically, holding everything else constant, just increasing the density of the population by 1% increases the crime rate by 0.48%, only increasing the young male population by 1% causes an increase in crime rate by 0.27%, increasing the minority population by 1% increase crime rate by 1.2%. The median wage and the log_prbarr (log of probability of arrest) have a negative effect on the crime rate. That is as the median wage increases by 1 unit, the crime decreases by 1% and while the probability of arrest increases by 1%, the crime rate decreases by 0.25%.

From the adjusted r-squared values we can clearly see an improvement from model1 to model2. 
While there is a modest increase in model3 when compared to model2, it does not justify the addition of two variables that are statistically insignificant. 

## Conclusions and Implications

Some model comparison

Note that we did not analyze police per capita (`polpc`), probablility of conviction (`prbcon`), probability of prison sentence (`prbpris`), average sentance (`avgsen`), or the offense mix (`mix`). There are several reasons we exlcuded `polpc` from our analysis. First, the number of police officers may be highly dependent on how much crime occurs in an area, and second, a county's resources, or wealth, could impact the number of police. Since we already have measures for wealth, and due to this possible confounding relationship between police and crime, we excluded the `polpc` varaible from analysis. `avgsen` and `mix` are more along the lines of a crime outcome, rather than a predictor of crime in an area. We chose between `prbarr`, `prbcon`, and `prbpris` as these variables measure similar events and including all three would be redundant. We also briefly analyze location variables (`west`, `central`, `urban`) below, but chose not to include them in this analysis.

From our analysis, we can conclude that the variables `log_density`, `log_pctmle` and `pctmin80` had the biggest impact on `crmrte`. Although these results are informative, no causal relationship can be drawn from our models. In general, regression itself does not imply causality; it's basis is in correlation. In this particular instance, this general rule holds. The data we have is observational, and no experiment was performed. However, we can still see that population density, demographics, and crime rate have a relationship.