---
title: 'Lab 4: Reducing Crime'
author: "Sullivan Swift, Jayanth Srinivasa"
date: "December 4, 2017"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(lmtest)
library(sandwich)
library(stargazer)

#set working directory
setwd("C:/Users/Sullivan/Dropbox/W203/Lab 4")

#load the data
crime <- read.csv("crime.csv")

variable <- c("county",
              "year",
              "crmrte",
              "prbarr",
              "prbconv",
              "prbpris",
              "avgsen",
              "polpc",
              "density",
              "taxpc",
              "west",
              "central",
              "urban",
              "pctmin80",
              "wcon",
              "wtuc",
              "wtrd",
              "wfir",
              "wser",
              "wmfg",
              "wfed",
              "wsta",
              "wloc",
              "mix",
              "pctymle")

label <- c("county identifier",
           "1987",
           "crimes committed per person",
           "`probability` of arrest",
           "`probability` of conviction",
           "`probability` of prison sentence",
           "avg. sentence, days",
           "police per capita ",
           "people per sq. mile",
           "tax revenue per capita",
           "=1 if in western N.C.",
           "=1 if in central N.C.",
           "=1 if in SMSA",
           "perc. minority, 1980",
           "weekly wage, construction",
           "wkly wge, trns, util, commun",
           "wkly wge, whlesle, retail trade",
           "wkly wge, fin, ins, real est",
           "wkly wge, service industry",
           "wkly wge, manufacturing",
           "wkly wge, fed employees",
           "wkly wge, state employees",
           "wkly wge, local gov emps",
           "offense mix: face-to-face/other",
           "percent young male")

desc <- data.frame(variable, label)
```

## 1. Introduction and Exploratory Analysis

To address questions regarding the determinants of crime in North Carolina in 1987, we conducted an analysis of the state's crime rate and possible related varaibles, including the following:

```{r}
#list the variables
desc
nrow(crime)
summary(crime) #No null values
```

We examined variables crime rate (`crmrte`), density per square mile (`density`), tax revenue per capita (`taxpc`), percent minority in 1980 (`pctmin80`), percent young male (`pctymle`), and probability of arrest (`prbarr`) as our main variables of interest. First, we performed a high level analysis to assess the quality of our data. We also wanted to examine wage data, so we calculated the median weekly wage (`med_wag`) for each county.

```{r, include=FALSE}
crime$med_wag <- apply(crime[,(16:24)],1, median, na.rm = TRUE)

C <- crime
filter = !is.na(C$crmrte) | !is.na(C$density) | !is.na(C$taxpc) | !is.na(C$pctmin80) | !is.na(C$pctymle) | !is.na(C$med_wag)
C = C[filter,]
summary(C)
nrow(C)

table(crime$west)
table(crime$central)
table(crime$urban)
```

There are no NA values. We also wanted to incorporate location into the analysis but these three variables did not create groups of even n, so we did not include location data in the analysis.

```{r}
summary(crime$crmrte)
hist(crime$crmrte, breaks=50,
     main="Histogram of crmrate")

summary(log(crime$crmrte))
hist(log(crime$crmrte), breaks=50,
     main="Histogram of log(crmrte)")

crime$log_crmrte <- log(crime$crmrte)
```

First we analyzed the outcome variable, crime rate(`crmrte`). In the original `crmrte` variable, the distribution is right tailed. We applied a log transformation to `crmrte`, and this variable had a more normal distribution. We chose to use the log of `crmrte` in our models below.

```{r}
summary(crime$density)
hist(crime$density, breaks=50,
     main="Histogram of Density per sq mile")

summary(log(crime$density))
hist(log(crime$density), breaks=50,
     main="Histogram of log(density)")

crime$log_density <- log(crime$density)
```

Next we examined density per square mile (`density`). There is a positive skew, so we again applied a log transformation. The log transformation of `density` is not quite normal, but since our $n=90$, we can rely on the Central Limit Theorem.

```{r}
summary(crime$taxpc)
hist(crime$taxpc, breaks=50,
     main="Histogram of Tax Paid per Capita")

summary(crime$med_wag)
hist(crime$med_wag, breaks=50,
     main="Histogram of Median Wages")
```

We then analyzed tax paid per capita (`taxpc`) and median wage (`med_wag`). We were concerned that these two variables have too much overlap in effect - wages are likely a very similar measure to the tax revenue per capita. After looking at the histograms of these two variables, we chose `med_wage` over `taxpc` because it is closer to a normal distribution.

```{r}
summary(crime$pctmin80)
hist(crime$pctmin80, breaks=50,
     main="Histogram of Percent Minority in 1980")

summary(crime$pctmin80)
hist(log(crime$pctmin80), breaks=50,
     main="Histogram of Percent Minority in 1980")
```

Next, we looked at percent minority in 1980 (`pctmin80`). 

```{r}
summary(crime$pctymle)
hist(crime$pctymle, breaks=50,
     main="Histogram of Percent Young Male")

summary(log(crime$pctymle))
hist(log(crime$pctymle), breaks=50,
     main="Histogram of log(pctymle)")

crime$log_pctymle <- log(crime$pctymle)
```

Then we examined the percentage of young males variable (`pctymle`). The values were all very small, between .06 and .25, and it appears to be in a decimal percentage format. `pctymle` also has a right skew. We address the skew, we transformed `pctymle` with a log. Using a log transformation we can also more easily interpret `pctymle` below in our models. 

```{r}
summary(crime$prbarr)
hist(log(crime$prbarr), breaks=50,
     main="Histogram of Probability of Arrest")
```

Lastly, we examined the probability of arrest (`prbarr`). It has a nice, normal distribution, and we saw no need to transform this variable.

```{r}
scatterplotMatrix(crime[,c('crmrte', 'density', 'med_wag', 'taxpc', 'pctmin80', 'pctymle', 'prbarr')])

(c <- with(crime, cor(cbind(crmrte, density, log_density, med_wag, taxpc, pctmin80, pctymle,log_pctymle, prbarr))))
```

Finally we examined a scatterplot matrix and correlation matrix to quickly assess the relationships between our variables. None of the variables we examined have a perfect correlation. Density has a fairly strong correlation with the `crmrte`, and so we used `density` as a key variable in our models below. We chose to include `med_wag`, but not `taxpc`. We chose to include pctmin80, and the transformation log(`pctymle`) over `pctymle`. We can use this correlation matrix to confirm MLR3, no perfect multicollinearity.

## Modeling Crime Rate and Addressing Assumptions

Addressing MLR1, the linearity assumption, the models we create below are linear in nature, so we meet this assumption.

Our sample appears to be nearly the entire population, and we ran into no NA values above. North Carolina has 100 counties, and our dataset contains 90. It contains enough of the population for us to assume MLR2, the assumption of random sampling.

We addressed MLR3 above.

We defined our first model hoping to keep to chose one or two key variables. We settled on log(`crmrte`) ~ log(`density`), as the more densely populated an area, the opportunity for crime to occur increases both from increased individuals and increased property in an area. Above we also see that `density` has a strong, positive correlation with `crmrte`.

```{r}
(model1 <- lm(log(crmrte) ~ log(density), data=crime))
plot(model1)

(se.model1 = sqrt(diag(vcovHC(model1))))

# 4'. Exo/Endogeneity
(cov(log(crime$density), model1$residuals))
#There is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0
plot(model1, which=1)

#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the residuals v fitted: fairly consistent but there are few data points on the extremes
#There is a small amount of edivdence for a violation, we will be cautious and use hetreoskedastic robust SE
plot(model1, which=3)
plot(model1, which=5)

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
plot(model1, which=2)
hist(model1$residuals, breaks = 100)
#normal, supporting IID
#qq plot, fairly normal except in extremes
```



```{r}
#SS
#2. log(crmrte) ~ log(density) + mpercent young males + pencent minority in 1980
(model2 <- lm(log(crmrte) ~ log(density) + log(pctymle) + pctmin80, data=crime))
plot(model2)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model2 = sqrt(diag(vcovHC(model2))))

# 4'. Exo/Endogeneity
plot(model2, which=1)
plot(model2, which=5)
(cov(log(crime$density), model2$residuals))
(cov(log(crime$pctymle), model2$residuals))
(cov(crime$pctmin80, model2$residuals))
#There is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0 - same as model 1


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the residuals v fitted: fairly consistent but is more varied on the extremes then model1
#There is a small amount of edivdence for a violation, we will be cautious and use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model2$residuals, breaks = 100)
#normal, supporting IID
#qq plot, fairly normal except in extremes - more normal than model1
```
. One model that includes the previous covariates, and most, if not all, other covariates. A key purpose of this model is to demonstrate the robustness of your results to model specification.
```{r}
#JS
#3. log(crmrte) ~ log(density) + pctymle + pctmin80 + taxpc + (maybe something location wise? the wages maybe? <- need to do EDA for wages)
(model3 <- lm(log(crmrte) ~ log(density) + log(pctymle) + pctmin80 + med_wag + log(prbarr), data=crime))
plot(model3)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model3 = sqrt(diag(vcovHC(model3))))

# 4'. Exo/Endogeneity
plot(model3, which=1)
plot(model3, which=5)
(cov(log(crime$density), model3$residuals))
(cov(log(crime$pctymle), model3$residuals))
(cov(crime$pctmin80, model3$residuals))
(cov(crime$med_wag, model3$residuals))
(cov(log(crime$prbarr), model3$residuals))
#all have is a very, very small correlation, indicating we can assume exogeneity.

# 4. Zero-conditional mean
#fitted v redisuals
#There is no evidence of a violation of this assumption, the red spline line very close to 0 - same as model 1
#left side has one point that pulls the mean down, otherwise zero mean


#5. homoskedasticity
# scale location plot
# we can't assume homoskedasticity because 
#band of the scale location: definitely heteroskedastic 
#use hetreoskedastic robust SE

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
hist(model3$residuals, breaks = 100)
#normal, supporting IID - has two fairly extreme points but mostly is together & normal
#qq plot, better fit than model 1 on the whole but has two very far outliers
```
## 6. Well formatted regression table (Stargazer?)

Make sure that standard errors presented in this table are valid. Also, be sure to comment on both statistical and practical significance.

```{r}
#JS
stargazer(model1, model2, model3, type = "text", omit.stat = "f",
          se = list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001))
#model1
#significant on log(density) at the .001 level. cool. practical & statistical

#model2
#two .01 level significance 
# holding all other things constant
#log(density) remains significant supporting it's use in the model - for each % change in density, there is a .51% change in crmrte
#practically and statistically significant
#log(pctmale) is also signicicant at the .001 level - for each % change in pctymle, there is a .388% change in crmrte
#pctmin80 significant - for each unit change in pctmin80, there is a 1.2% change in crmrte
#seems to be the best
#practically significant - almost a one to one increase

#model3
#very similar interpretation to moel 2 + two insiginificant additional vairables
#log(density) remains significant supporting it's use in the model - for each % change in density, there is a .48% change in crmrte
#practically and statistically significant
#log(pctmale) is also signicicant at the .05 level - for each % change in pctymle, there is a .277% change in crmrte
#pctmin80 significant - for each unit change in pctmin80, there is a 1.2% change in crmrte
#med wage - not siginificant - the beta is negative - for each unit change (thousands of dollars) in med_wag, there is a -.1% change in crmrte
#would be practically significant, but not statistically significant
#log(prbarr) - not significant - the beta is negative - or each % change in density, there is a -.249% change in crmrte
#would be practically signgifcant
#because the additional variables are not significant, we have support for using model 2

```

## 7. Discussion of Causality

In particular, include a discussion of what variables are not included in your analysis and the likely direction of omitted variable bias. Highlight any coefficients you find that appear to have the wrong sign from a causal perspective, and explain why this is the case.

I don't think we can talk in terms of causality. the data isn't collected in an experiment format, it's observational. 

## 8. Brief Conclusion with high-level takeaways

