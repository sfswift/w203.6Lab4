---
title: "Lab 4: Reducing Crime"
author: "Sullivan Swift, Jayanth Srinivasa"
date: "December 4, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(lmtest)
library(sandwich)
library(stargazer)

#set working directory
setwd("C:/Users/Sullivan/Dropbox/W203/Lab 4")

#load the data
crime <- read.csv("crime.csv")

variable <- c("county",
              "year",
              "crmrte",
              "prbarr",
              "prbconv",
              "prbpris",
              "avgsen",
              "polpc",
              "density",
              "taxpc",
              "west",
              "central",
              "urban",
              "pctmin80",
              "wcon",
              "wtuc",
              "wtrd",
              "wfir",
              "wser",
              "wmfg",
              "wfed",
              "wsta",
              "wloc",
              "mix",
              "pctymle")

label <- c("county identifier",
           "1987",
           "crimes committed per person",
           "‘probability’ of arrest",
           "‘probability’ of conviction",
           "‘probability’ of prison sentence",
           "avg. sentence, days",
           "police per capita ",
           "people per sq. mile",
           "tax revenue per capital",
           "=1 if in western N.C.",
           "=1 if in central N.C.",
           "=1 if in SMSA",
           "perc. minority, 1980",
           "weekly wage, construction",
           "wkly wge, trns, util, commun",
           "wkly wge, whlesle, retail trade",
           "wkly wge, fin, ins, real est",
           "wkly wge, service industry",
           "wkly wge, manufacturing",
           "wkly wge, fed employees",
           "wkly wge, state employees",
           "wkly wge, local gov emps",
           "offense mix: face-to-face/other",
           "percent young male")

desc <- data.frame(variable, label)
```

## 1. Introduction

To address questions regarding the determinants of crime in North Carolina in 1987, we conducted an analysis of the state's crime rate and possible related varaibles, including the following:

```{r}
#list the variables
desc
nrow(crime)
summary(crime) #No null values
```

We chose to examine variables `crmrte`, `polpc`, `density`, `taxpc`, `pctmin80`, and `pctymle` [SS/JS: ADD OTHER VARIABLES]. First, we removed performed a high level analysis to assess the quality of our data.

```{r, include=FALSE}
#Check for NAs UPDATE
C <- crime
filter = !is.na(C$crmrte) | !is.na(C$polpc) | !is.na(C$density) | !is.na(C$taxpc) | !is.na(C$pctmin80) | !is.na(C$pctymle)
C = C[filter,]
summary(C)
nrow(C)
```

```{r}
summary(crime)

#county
summary(crime$county)
hist(crime$county)

#crimerate
summary(crime$crmrte)
hist(crime$crmrte)
#long right tail
summary(log(crime$crmrte))
hist(log(crime$crmrte))
#makes it more normal

#police per capita
summary(crime$polpc)
hist(crime$polpc)
#extreme outlier on the right

#density per sq mile
summary(crime$density)
hist(crime$density)
#abrupt cut off on the right at 0, try log
summary(log(crime$density))
hist(log(crime$density))
#better but still not entirely normal
#n > 30, not gonna worry about it

#counties seems like too many numbers to use
#will try west/central or urban as on identifiers 
table(crime$west)
table(crime$central)
table(crime$urban)
#well those numbers aren't equal
#I just don't feel like we can ignore different areas in the state 

#tax revenue per capita
summary(crime$taxpc)
hist(crime$taxpc, breaks = 100)
#outlier to the far right, wtf - wonder if it's the same county

summary(log(crime$taxpc))
hist(log(crime$taxpc), breaks = 100)

#pctmin80 - might be too far back in time? or that's a concern anyway
summary(crime$pctmin80)
hist(crime$pctmin80)

#pctymle - % young male
summary(crime$pctymle)
hist(crime$pctymale)

## Creating a median_wage column :
crime$med_wag <- apply(crime[,(16:24)],1, median, na.rm = TRUE)
summary(crime$med_wag)
hist(crime$med_wag)
hist(log(crime$med_wag))

## If we assume the probability of conviction and arrest, is a deterrent to crime we can create a new variable that gives the probability of conviction after arrest, i.e the multiple  of the probability of arrest and probability of conviction.
crime$prbconv_prbarr <-  crime$prbarr*crime$prbconv
summary(crime$prbconv_prbarr)
hist(crime$prbconv_prbarr)

summary(crime$prbarr)
hist(log(crime$prbarr), breaks=100)
summary(crime$prbconv)
cor(crime$crmrte, crime$prbarr)
plot(crime$prbarr, crime$crmrte)

#This clearly shows us that it is skewed and if we take a log of this we get 
crime$log_prbconv_prbarr <- log(crime$prbconv_prbarr)
summary(crime$log_prbconv_prbarr)
hist(crime$log_prbconv_prbarr)

#leaving out prison sentences and mix - they seem like the outcome variables mentioned below

#Assumptions to address
#1. Linear

# 2. Random sampling
durbinWatsonTest(model)

#3. no perfect multicolinearity
(c <- with(crime, cor(cbind(crmrte, polpc, density, log(density), taxpc, pctmin80, pctymle))))
```

## 2. Initial exploratory analysis

Detect any anomalies, including missing values, top-coded or bottom-
coded variables, etc.

Model Building Process is supported by exploratory analysis. Your EDA should be interspersed with, and support, your modeling decisions. In particular, you should use exploratory techniques to address

. What transformations to apply to variables and what new variables should be created.

. What variables should be included in each model

. Whether model assumptions are met

```{r}
#correlations and scatterplots
#I'm not like totally sure if we need to check log(density) in these
(c <- with(crime, cor(cbind(crmrte, density, log(density), med_wag, log(med_wag), taxpc, log(taxpc), pctmin80, pctymle))))
#density and crime rate are the only ones super correlated (.73), crime rate and tax per capita are .45, which isn't bad but isn't great. density x taxpc = .32

scatterplotMatrix(crime[,c('crmrte', 'polpc', 'density', 'med_wag', 'taxpc', 'pctmin80', 'pctymle')])
```


## 4. Three model specifications

One model with only the explanatory variables of key interest (possibly transformed, as determined by your EDA), and no other covariates.
```{r}
#1. log(crmrte) ~ log(density)
(model1 <- lm(log(crmrte) ~ log(density), data=crime))
plot(model1)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model1 = sqrt(diag(vcovHC(model1))))

# 4'. Exo/Endogeneity

# 4. Zero-conditional mean
plot(model)

#fitted v redisuals

#5. homoskedasticity
# scale location plot

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
```
. One model that includes key explanatory variables and only covariates that you believe increase the accuracy of your results without introducing bias (for example, you should not include outcome variables that will absorb some of the causal effect you are interested in). This model should strike a balance between accuracy and parsimony and reflect your best understanding of the determinants of crime.
```{r}
#2. log(crmrte) ~ log(density) + med_wage
(model2 <- lm(log(crmrte) ~ log(density) + pctymle + pctmin80, data=crime))
plot(model2)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model2 = sqrt(diag(vcovHC(model2))))

# 4'. Exo/Endogeneity

# 4. Zero-conditional mean
plot(model)

#fitted v redisuals

#5. homoskedasticity
# scale location plot

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
```
. One model that includes the previous covariates, and most, if not all, other covariates. A key purpose of this model is to demonstrate the robustness of your results to model specification.
```{r}
#3. log(crmrte) ~ log(density) + pctymle + pctmin80 + taxpc + (maybe something location wise? the wages maybe? <- need to do EDA for wages)
(model3 <- lm(log(crmrte) ~ log(density) + pctymle + pctmin80 + med_wag + log(taxpc) + polpc + log(prbarr), data=crime))
plot(model3)
#check the assumptions the graphs do

#Using errors robust to heteroskedasticity - for stargazer
(se.model3 = sqrt(diag(vcovHC(model3))))

# 4'. Exo/Endogeneity

# 4. Zero-conditional mean
plot(model)

#fitted v redisuals

#5. homoskedasticity
# scale location plot

# 6. IID normal error, hist of residuals, qqplot of residuals
#plot(model)
```
## 5. Test 6 CLM

For additional models, you
should check all assumptions, but only highlight major differences from your first model in your report.
1. Linear Model
2. Random Sample
3. No perfect colinearity
4. Zero Conditional mean
4'. Exogeneity (I don't think we need to worry about this one?)
5. Homoskedasticity
6. IID normal error

## 6. Well formatted regression table (Stargazer?)

Make sure that standard errors presented in this table are valid. Also, be sure to comment on both statistical and practical significance.

```{r}
stargazer(model1, model2, model3, type = "text", omit.stat = "f",
          se = list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001))
```

## 7. Discussion of Causality

In particular, include a discussion of what variables are not included in your analysis and the likely direction of omitted variable bias. Highlight any coefficients you find that appear to have the wrong sign from a causal perspective, and explain why this is the case.

## 8. Brief Conclusion with high-level takeaways
